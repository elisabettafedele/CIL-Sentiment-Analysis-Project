{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LSTM\nThe aim of this notebook is implementing LSTM for sentyment analysis of tweets.\n\n","metadata":{"id":"Xu9OYKi2mTNn"}},{"cell_type":"markdown","source":"# 1. Setup","metadata":{"id":"Z-NKrC3Cnyj6"}},{"cell_type":"markdown","source":"## 1.1 Imports","metadata":{}},{"cell_type":"code","source":"# Imports \n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n\nimport re","metadata":{"id":"20A0j831gE9i","execution":{"iopub.status.busy":"2022-07-30T15:51:47.852712Z","iopub.execute_input":"2022-07-30T15:51:47.853191Z","iopub.status.idle":"2022-07-30T15:51:47.968106Z","shell.execute_reply.started":"2022-07-30T15:51:47.853155Z","shell.execute_reply":"2022-07-30T15:51:47.966543Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Define some useful functions","metadata":{}},{"cell_type":"code","source":"def load_tweets(filename, label):\n    with open(filename, 'r', encoding='utf-8') as f:\n        for line in f:\n            tweets.append(line.rstrip())\n            labels.append(label)\n    return np.array(tweets)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:46:43.236886Z","iopub.execute_input":"2022-07-30T15:46:43.237562Z","iopub.status.idle":"2022-07-30T15:46:43.245536Z","shell.execute_reply.started":"2022-07-30T15:46:43.237526Z","shell.execute_reply":"2022-07-30T15:46:43.244005Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_test_tweets(filename):\n  tweets = []\n  with open(filename, 'r', encoding='utf-8') as f:\n        for line in f:\n            tweets.append(line.rstrip())\n  return tweets","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:46:43.248815Z","iopub.execute_input":"2022-07-30T15:46:43.249204Z","iopub.status.idle":"2022-07-30T15:46:43.270264Z","shell.execute_reply.started":"2022-07-30T15:46:43.249171Z","shell.execute_reply":"2022-07-30T15:46:43.269006Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Setup input and output paths","metadata":{"id":"ngaOuI6Yn1_Z"}},{"cell_type":"code","source":"input_data_path = '../input/cil-processed-dataset/'\noutput_data_path = 'submissions/'","metadata":{"id":"aKlvQUDCofmI","execution":{"iopub.status.busy":"2022-07-30T15:46:43.271829Z","iopub.execute_input":"2022-07-30T15:46:43.272509Z","iopub.status.idle":"2022-07-30T15:46:43.282380Z","shell.execute_reply.started":"2022-07-30T15:46:43.272474Z","shell.execute_reply":"2022-07-30T15:46:43.281213Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Set an LSTM type","metadata":{}},{"cell_type":"code","source":"lstm_out = 196","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:46:43.285641Z","iopub.execute_input":"2022-07-30T15:46:43.286340Z","iopub.status.idle":"2022-07-30T15:46:43.292573Z","shell.execute_reply.started":"2022-07-30T15:46:43.286291Z","shell.execute_reply":"2022-07-30T15:46:43.291416Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# If you wish to use a bidirectional LSTM set bidirectional_LSTM = True\n# If you wish to use a vanilla LSTM set bidirectional_LSTM = False\nbidirectional_LSTM = True\n\n#If you wish to stack two LSTM of the type defined before set stacked_LSTM = True\nstacked_LSTM = False\n\nif(bidirectional_LSTM):\n    LSTMLayer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n    LSTMLayer_stacked = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\nelse:\n    LSTMLayer = LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)\n    LSTMLayer_stacked = LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:46:59.933127Z","iopub.execute_input":"2022-07-30T15:46:59.933853Z","iopub.status.idle":"2022-07-30T15:47:00.056546Z","shell.execute_reply.started":"2022-07-30T15:46:59.933816Z","shell.execute_reply":"2022-07-30T15:47:00.054844Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 1.4 Load tweets from the dataset","metadata":{}},{"cell_type":"code","source":"tweets = []\nlabels = []\nload_tweets(input_data_path + 'processed_neg.txt', 0)\nload_tweets(input_data_path + 'processed_pos.txt', 1)\n\n# Convert to NumPy array\ntweets = np.array(tweets)\nlabels = np.array(labels)\n\nprint(f'{len(tweets)} tweets loaded')","metadata":{"id":"Kb_n11mjTo_W","execution":{"iopub.status.busy":"2022-07-30T15:47:02.389432Z","iopub.execute_input":"2022-07-30T15:47:02.389970Z","iopub.status.idle":"2022-07-30T15:47:12.412767Z","shell.execute_reply.started":"2022-07-30T15:47:02.389927Z","shell.execute_reply":"2022-07-30T15:47:12.411610Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Check now the length of the tweets loaded. \n\nIn particular, remind that:\n- Small training set consists on 200.000 tweets\n- Complete training set consists on 2.500.000 tweets","metadata":{}},{"cell_type":"code","source":"data = pd.DataFrame(columns = ['text', 'sentiment'], data=np.array([tweets, labels]).T)","metadata":{"id":"yK-ltRdyV5WK","execution":{"iopub.status.busy":"2022-07-30T15:47:12.414590Z","iopub.execute_input":"2022-07-30T15:47:12.414927Z","iopub.status.idle":"2022-07-30T15:47:24.648922Z","shell.execute_reply.started":"2022-07-30T15:47:12.414889Z","shell.execute_reply":"2022-07-30T15:47:24.647648Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# 2. Tokenize the data","metadata":{}},{"cell_type":"code","source":"max_features = 5000\ntokenizer = Tokenizer(num_words=max_features, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\n","metadata":{"id":"2LbEwgVaYcmF","execution":{"iopub.status.busy":"2022-07-30T15:47:47.042068Z","iopub.execute_input":"2022-07-30T15:47:47.043731Z","iopub.status.idle":"2022-07-30T15:49:36.491397Z","shell.execute_reply.started":"2022-07-30T15:47:47.043684Z","shell.execute_reply":"2022-07-30T15:49:36.490117Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"lens = []\nfor el in X:\n  lens.append(len(el))\n\nsns.displot(np.array(lens), color = 'orange')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:51:52.630832Z","iopub.execute_input":"2022-07-30T15:51:52.631273Z","iopub.status.idle":"2022-07-30T15:51:56.642635Z","shell.execute_reply.started":"2022-07-30T15:51:52.631236Z","shell.execute_reply":"2022-07-30T15:51:56.641546Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X = pad_sequences(X, maxlen = 25)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:51:56.644360Z","iopub.execute_input":"2022-07-30T15:51:56.644894Z","iopub.status.idle":"2022-07-30T15:52:08.871227Z","shell.execute_reply.started":"2022-07-30T15:51:56.644858Z","shell.execute_reply":"2022-07-30T15:52:08.870062Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# 3. Define the model","metadata":{}},{"cell_type":"code","source":"embed_dim = 100\ninput_length = X.shape[1]\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_dim, input_length = input_length))\nmodel.add(SpatialDropout1D(0.4))\nif stacked_LSTM:\n    model.add(LSTMLayer_stacked)  \nmodel.add(LSTMLayer)\nmodel.add(Dense(2,activation='softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","metadata":{"id":"PnVtumo7U6-0","outputId":"ece2545b-4ee7-4375-8dc0-aad2095ead04","execution":{"iopub.status.busy":"2022-07-26T21:35:02.369780Z","iopub.execute_input":"2022-07-26T21:35:02.370257Z","iopub.status.idle":"2022-07-26T21:35:03.059859Z","shell.execute_reply.started":"2022-07-26T21:35:02.370220Z","shell.execute_reply":"2022-07-26T21:35:03.058510Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"Y = pd.get_dummies(data['sentiment']).values\nX_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size = 0.1, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_val.shape,Y_val.shape)","metadata":{"id":"UUfk5QuuZLT3","outputId":"41a5c204-cd40-4836-a98e-8b7669d744eb","execution":{"iopub.status.busy":"2022-07-26T21:35:03.062139Z","iopub.execute_input":"2022-07-26T21:35:03.062524Z","iopub.status.idle":"2022-07-26T21:35:04.151311Z","shell.execute_reply.started":"2022-07-26T21:35:03.062487Z","shell.execute_reply":"2022-07-26T21:35:04.149794Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# 4. Train the model ","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nhistory = model.fit(X_train, Y_train, epochs = 3, validation_data = [X_val, Y_val], \n                    steps_per_epoch = 100, batch_size = batch_size, verbose = 1)","metadata":{"id":"hQ6hxsBuZNLd","outputId":"70abe6a1-21e2-4d46-aae9-dc20815e0cf3","execution":{"iopub.status.busy":"2022-07-26T21:35:04.153252Z","iopub.execute_input":"2022-07-26T21:35:04.154946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplot_graphs(history, 'accuracy')\nplt.ylim(None, 1)\nplt.subplot(1, 2, 2)\nplot_graphs(history, 'loss')\nplt.ylim(0, None)\n#plt.savefig('training.png')","metadata":{"id":"xdZtVANqfZu0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Make submissions","metadata":{}},{"cell_type":"code","source":"X_test = load_test_tweets(input_data_path + 'processed_test_no_idx.txt')\ntokenized_test = tokenizer.texts_to_sequences(X_test)\npadded = pad_sequences(tokenized_test, maxlen=X.shape[1], dtype='int32', value=0)","metadata":{"id":"S8qe91jM6TCO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiments = model.predict(padded,batch_size=len(X_test))","metadata":{"id":"tiptbFkU6tev","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor sent in sentiments:\n  pred = np.argmax(sent)\n  if (pred == 0):\n    predictions.append(-1)\n  else:\n    predictions.append(1)\n\ndf = pd.DataFrame(np.array(predictions), columns=[\"Prediction\"])\ndf.index.name = \"Id\"\ndf.index += 1\ndf.to_csv(output_data_path + \"submission_LSTM.csv\")","metadata":{"id":"cMnzsZzA1rzu","trusted":true},"execution_count":null,"outputs":[]}]}